{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "Two previous parts"}, {"metadata": {}, "cell_type": "code", "source": "from bs4 import BeautifulSoup\nimport requests\nimport html.parser\nimport pandas as pd\nimport numpy as np\n!conda install -c conda-forge folium=0.5.0 --yes\nimport folium\nfrom geopy.geocoders import Nominatim\nfrom pandas.io.json import json_normalize\nimport csv                  \nimport webbrowser\nimport io\nurl='https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\ncols=['PostalCode','Borough','Neighborhood']\nsession=requests.Session()\nr = session.get(url)\nsoup=BeautifulSoup(r.text, 'html.parser')\ntable=soup.find('table', class_='wikitable')\noutput_rows = []\nfor table_row in table.findAll('tr'):\n    columns = table_row.findAll('td')\n    output_row = []\n    for column in columns:\n        output_row.append(column.text)\n    output_rows.append(output_row)\noutput_rows=output_rows[1:]\ndef stripping(lst):\n    return [value.rstrip() for value in lst]\nresult=list(map(stripping,output_rows))\nnewresult=list(filter(lambda x: x[1]!='Not assigned',result))\ndf=pd.DataFrame(newresult, columns=cols)\ndf.sort_values(by='PostalCode')\ncoords=pd.read_csv('http://cocl.us/Geospatial_data')\ndf=df.sort_values(by='PostalCode')\nnewdf=df.reset_index(drop=True)\nnewdf['Latitude']=coords['Latitude']\nnewdf['Longitude']=coords['Longitude']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Coords to center a map"}, {"metadata": {}, "cell_type": "code", "source": "from geopy.geocoders import Nominatim\naddress = 'Toronto, CA'\n\ngeolocator = Nominatim(user_agent=\"tor_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\n# print('The geograpical coordinate of Toronto are {}, {}.'.format(latitude, longitude))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Plotting map of these neighborhoods", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "map_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(newdf['Latitude'], newdf['Longitude'], newdf['Borough'], newdf['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_toronto)  \n    \nmap_toronto", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Foursquare API credentials"}, {"metadata": {}, "cell_type": "code", "source": "CLIENT_ID = 'VUNTF3ZSXSLZUKZT2E45GMW21D5HJHGK5PVG0Z3MZCTAPWF3' # your Foursquare ID\nCLIENT_SECRET = 'GTGDFDX54B2VVS512W5VPQYR5KITNTUNUQ3XUAZIZZZYJVBU' # your Foursquare Secret\nVERSION = '20180605' # Foursquare API version\ncategories={'Arts & Entertainment': '4d4b7104d754a06370d81259',\n            'College & University':'4d4b7105d754a06372d81259',\n            'Event':'4d4b7105d754a06373d81259',\n            'Food':'4d4b7105d754a06374d81259',\n            'Nightlife Spot':'4d4b7105d754a06376d81259',\n            'Outdoors & Recreation':'4d4b7105d754a06377d81259',\n            'Professional & Other Places':'4d4b7105d754a06375d81259',\n            'Residence':'4e67e38e036454776db1fb3a',\n            'Travel & Transport':'4d4b7105d754a06379d81259'}\n\n\n\nprint('Your credentials:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# FUnction for explori\u043fg venues in neighborhoods (actually not in, but around it's coordinates)\n\ndef explore_NH(neighborhoods, radius=500,LIMIT=100):\n    result=[]\n    for i,lst in enumerate(zip(neighborhoods['Neighborhood'],neighborhoods['Latitude'],neighborhoods['Longitude'])):\n        names=lst[0]\n        lat=lst[1]\n        long=lst[2]\n        to_append=[names,lat,long]\n#         for cats in list(categories.items()):\n#             categ=cats[0]\n#             catId=cats[1]\n        url= 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n        CLIENT_ID, \n        CLIENT_SECRET, \n        VERSION, \n        lat, \n        long, \n        radius, \n        LIMIT)\n        request_result=requests.get(url).json()\n        result.append(request_result)\n#         try:\n#             to_append.append(len(request_result['response']['venues'])) \n#         except KeyError:\n#             print('----------------------------------------------------------------')\n#             print(lat, long)\n#             print(requests.get(url).json())\n#             print('OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO')\n#         result.append(to_append)\n    return result\n    \n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Initial results"}, {"metadata": {}, "cell_type": "code", "source": "results = explore_NH(newdf)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Checking results"}, {"metadata": {}, "cell_type": "code", "source": "results[0]['response']['groups'][0]['items'][0]['venue']['categories'][0]['id']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "count=0\nfor i,qwe in enumerate(results):\n    if len(qwe['response']['groups'][0]['items'])>0:\n        count+=1\nprint(count)\nprint(len(results))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<!-- As you can see there are 100 neighborhoods where are some venues in results.  -->"}, {"metadata": {}, "cell_type": "markdown", "source": "<!-- Cell below needed to count number of venues and add new column to dataframe -->"}, {"metadata": {}, "cell_type": "code", "source": "amount=[]\nfor i in results:\n    amount.append(len(i['response']['groups'][0]['items']))\n\nnewdf['Venues_count']=amount\n\nprint(newdf.head(10))\nnewdf.tail(10)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "I don't want to replicate NY analysis, so here is slightly different analysis"}, {"metadata": {}, "cell_type": "code", "source": "# Firstly I want to get number of venues in different categories for all neighborhoods\n\n# How?\n\n# I need categories' ids from foursquare.com (https://developer.foursquare.com/docs/build-with-foursquare/categories/)\n# I need to scrape them (it's not that easy cus of this page on foursquare.com got interesting structure)\n# Next step is to transform this information into useful form - dictionary\n\ndef check_hierarchy(to_check):\n    if to_check.find_all(\"li\")==[]:\n        return 0\n    else:\n        return 1\n    \ndef to_dict(cats):\n    dict_={}\n    names=[]\n    for zero in cats:\n        name_0,cat_0 = zero[0]\n#         print(name_0)\n        names.append([name_0,cat_0])\n        dict_[cat_0]=name_0\n        for first in zero[1]:\n            if type(first[1]) == list:\n                dict_[first[0][1]]=zero[0][1]\n                for second in first[1]:\n                    if type(second[1]) == list:\n                        dict_[second[0][1]] = first[0][1]\n                        for third in second[1]:\n                            dict_[third[1]] = second[0][1]\n                    else:\n                        dict_[second[1]] =first[0][1]\n                    \n            else:\n                dict_[first[1]] = zero[0][1]\n#     for name,cat in names:\n#         print(dict_[cat]==name)\n#         if name in dict_.values():\n#             print(name, ' OK')\n#         else:\n#             print(name, ' NOT OK')\n    return dict_\n\n\ndef get_venue_categories_dict():\n    url = 'https://developer.foursquare.com/docs/build-with-foursquare/categories/'\n    session = requests.Session()\n    r = session.get(url)\n    soup = BeautifulSoup(r.text, 'html')\n    main_wrapper = soup.find('ul', class_=\"VenueCategories__Wrapper-sc-1ysxg0y-0 bYmzDC\")\n    current = main_wrapper.li\n    level_0 = []\n    while current != None:\n        cat_0 = [str(current.h3.string), str(current.p.string)]\n        level_0.append(cat_0)\n        to_unpack = list(current.div.children)[-1]\n        current_1 = to_unpack.li\n        level_1 = []\n        while current_1 != None:\n            cat_1 = [str(current_1.h3.string), str(current_1.p.string)]\n            level_1.append(cat_1)\n            if check_hierarchy(current_1):\n                current_2 = current_1.li\n                level_2=[]\n                while current_2 != None:\n                    cat_2 = [str(current_2.h3.string), str(current_2.p.string)]\n                    level_2.append(cat_2)\n                    if check_hierarchy(current_2):\n                        level_3 = []\n                        current_3 = current_2.li\n                        while current_3 != None:\n                            cat_3 = [str(current_3.h3.string), str(current_3.p.string)]\n                            level_3.append(cat_3)\n                            current_3 = current_3.next_sibling\n                        level_2[-1] = [level_2[-1], level_3]\n                    current_2 = current_2.next_sibling\n                level_1[-1] = [level_1[-1], level_2]\n                                       \n            current_1 = current_1.next_sibling\n        level_0[-1] = [level_0[-1], level_1]\n        current = current.next_sibling\n    return to_dict(level_0)\n\n\n\n\n# Then I need to get main category name using venue's category id\n\ndef find_main_category(cat, cat_dict):\n#     print('CCCCCCCCCAAAAAAAAAAAATTTTTTTTTTTTTT')\n#     print(cat)\n    if cat_dict[cat] in cat_dict.keys():\n        return find_main_category(cat_dict[cat], cat_dict)\n    else: return cat_dict[cat]\n    \n# Now I can get main category name to add columns to dataframe and count number of venues of each category in every NH\n\ndef get_categories(data, response, cat_dict):\n    for i in range(len(data)):\n        ids = []\n        for venue in results[i]['response']['groups'][0]['items']:\n            ids.append(venue['venue']['categories'][0]['id'])\n        dict0={}\n        for id_ in ids:\n            ID = find_main_category(id_, cat_dict)\n            if ID in dict0.keys():\n                dict0[ID] += 1\n            else:\n                dict0[ID] = 1\n        for name, val in dict0.items():\n            data.loc[i,name] = val\n    return data", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "newdf.drop(labels='ids', axis=1, inplace=True)\nget_categories(newdf, results, get_venue_categories_dict())", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "newdf.fillna(0, inplace=True)\nnewdf", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Now I will go right to clustering because frequency analysis here is pretty irrelevant"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.cluster import KMeans\n\nkclusters = 6\n\nkmeans = KMeans(n_clusters=kclusters, random_state=13).fit(newdf.iloc[:, -9:])\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[20:40]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# add clustering labels\n\nmerged=pd.DataFrame(index=newdf.index)\nmerged['Latitude']=newdf['Latitude']\nmerged['Longitude']=newdf['Longitude']\nmerged['Cluster Labels']=kmeans.labels_\nnewdf.insert(newdf.shape[1], 'Cluster Labels', kmeans.labels_)\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\nmerged.head() # check the last columns!\n\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# create map\n\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(merged['Latitude'], merged['Longitude'], merged.index, merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster],\n        fill=True,\n        fill_color=rainbow[cluster],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}